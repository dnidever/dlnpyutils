#!/usr/bin/env python
#
# JOB_DAEMON.PY - Simple batch job manager.
#

from __future__ import print_function

__authors__ = 'David Nidever <dnidever@noao.edu>'
__version__ = '20181010'  # yyyymmdd

import os
import sys
import numpy as np
import warnings
import socket
#from astropy.io import fits
#from astropy.wcs import WCS
#from astropy.utils.exceptions import AstropyWarning
#from astropy.table import Table, Column
import time
#import shutil
import subprocess
#import logging
#import astropy.stats
#import struct
#import tempfile
from dlnpyutils.dlnpyutils import *

        
def mkstatstr(n=None):
    """ This returns the stat structure schema or an instance of the job structure."""
    dtype = np.dtype([('jobid',np.str,20),('name',np.str,100),('user',np.str,100),('timeuse',np.str,100),('status',np.str),('queue',np.str)])
    if n is None:
        return dtype
    else:
        statstr = np.zeros(n,dtype=dtype)    
        return statstr

def mkjobstr(n=None):
    """ This returns the job structure schema or an instance of the job structure."""
    dtype = np.dtype([('host',np.str,20),('jobid',(np.str,100)),('input',np.str,100),('dir',np.str,100),('name',np.str,100),('scriptname',np.str),
                      ('logfile',np.str),('submitted',np.bool),('done',np.bool),('begtime',np.float64),('endtime',np.float64),('duration',float)])
    if n is None:
        return dtype
    else:
        jobstr = np.zeros(n,dtype=dtype)    
        return jobstr


def check_diskspace(indir=None,updatestatus=False):
    """ This checks if there's enough free disk space. """
    if indir is None: raise ValueError("Must give directory")
    statvfs = os.statvfs(indir)
    available = statvfs.f_frsize * statvfs.f_bavail / 1e6  # in MB
    if updatestatus: print,'Disk Space: '+str(available[0]),' MB available'
    # Not enough disk space available
    if available<100.:
        raise Exception('NOT enough disk space available')


def check_killfile(jobs=None,hyperthread=True):
    """ This checks for a kill file and if found kills all the active jobs. """
    if jobs is None: raise ValueError("No jobs structure input")
    killfile = 'killjobs'
    if os.path.exists(killfile) is True:
        sub = np.where((jobs['submitted']==1) & (jobs['done']==0))
        nsub = len(sub)
        print('Kill file found.  Killing all '+str(nsub)+' job(s)')
        for i=0,nsub-1:
            # Killing the job
            print('Killing '+jobs[sub[i]]['name']+'  JobID='+jobs[sub[i]]['jobid'])
            if hypterthread is False:
                out = subprocess.check_output(['qdel',jobs[sub[i]]['jobid']],stdout=sf,stderr=subprocess.STDOUT,shell=False)
            else:
                out = subprocess.check_output(['kill','-9',jobs[sub[i]]['jobid']],stderr=subprocess.STDOUT,shell=False)
        # Remove the kill file
        print('Deleting kill file "'+killfile+'"')
        os.remove(killfile)
        sys.exit()


def makescript(input=None,indir=None,name=None,scriptname=None,idle=False,prefix=None,hyperthread=True)
    """This makes job scripts for the job_daemon program.

    Parameters
    ----------
    input : string list or array
          The command to execute.  Can be an array.  idlbatch will
          be used if it's an IDL command.  If the command is a
          series of unix commands separated by commas then these
          will be put on separate lines.
    indir : string list or array
          The directory to put the job script in.
    name : string list or array, optional
          The name to call the job script (without the '.sh' or '.batch' ending).
          If this is not provided then an autogenerated name will
          be made and returned.
    idle : bool, optional
          This is an IDL command, otherwise a SHELL command.
    prefix : string, optional
          The prefix to use for the job script name. "pr" by default.
    hyperthread : bool 
          Not on a job server but one with multiple hyperthreaded
                   processors.

    Returns
    -------
    scriptname : string array
               The absolute names of the scripts.
    Job scripts output to the directories and with the names specified.


    Example
    -------

    .. code-block:: python

        scriptname = makescript(input,dir,name,hyperthread=True)

    """
  
    # Not enough inputs
    if (input is None):
        raise ValueError('No input given')

    ninput = np.array(input).size
    if indir is not None: ndir=np.array(indir).size else ndir=0
    if name is not None: nname=np.array(name).size else nname=0

    # Not enough directories input
    if (ndir>0) & (ndir!=ninput):
        raise ValueError('INPUT and DIRECTORIES are of different size')

    # Current directory
    curdir = os.getcwd()

    # No directories input
    if ndir==0: indir = np.repeat(curdir,ninput)
    if ndir==1: indir = np.repeat(indir,ninput)    # multiple commands in same dir

    # Construct names
    if (nname==0):
        name = np.zeros(ninput,dtype=(np.str,200))
        if prefix is not None:
            pre = prefix[0]
        else:
            pre = 'job'
        for i in range(ninput):
            tid,tfile = tempfile.mkstemp(prefix=pre,dir=indir[i])
            os.close(tid)   # mkstemp opens the file, close it
            name[i] = tfile

    # Make scriptnames
    scriptname = strjoin(strjoin(indir,name),'.sh')
    # Script loop
    for i in range(ninput):
        base = str(name[i])
        sname = str(indir[i])+'/'+base+'.sh'

        #------
        # PBS
        #------
        if hyperthread is False:
            # IDL command
            if idle is True:
                # Making an IDL batch file
                bname = str(indir[i])+'/'+base+'.batch'
                writelines(bname,input[i])
                # The execution command
                cmd = 'idl < '+base+'.batch'
            # SHELL command
            else:
                # The execution command
                cmd = input[i]
                # If there are commas in the line then break it up into multiple lines
                if cmd.find(';') != -1: cmd = cmd.split('j')

            # Make the command
            #----------------------
            lines = []
            lines.append('#!/bin/sh\n')
            lines.append('#PBS -l nodes=1:ppn=1\n')
            lines.append('#PBS -l walltime=96:00:00\n')
            lines.append('#PBS -o '+base+'.report.out\n')
            lines.append('#PBS -e '+base+'.error.out\n')
            lines.append('#PBS -M dln5q@virginia.edu\n')
            lines.append('#PBS -V\n')
            lines.append('\n')
            lines.append('echo Running on host `hostname`\n')
            lines.append('echo Time is `date`\n')
            lines.append('echo "Nodes used for this job:"\n')
            lines.append('echo "------------------------"\n')
            lines.append('cat $PBS_NODEFILE\n')
            lines.append('echo "------------------------"\n')
            lines.append('\n')
            lines.append('cd '+indir[i]+'\n')
            for j in range(len(cmd)): lines.append(cmd[j]+'\n')
            lines.append('\n')
            lines.append('# print end time\n')
            lines.append('echo\n')
            lines.append('echo "Job Ended at `date`"\n')
            lines.append('echo\n')
            # Writing the file
            writelines(scriptname[i],lines)
            # Print info
            print('PBS script written to: '+str(scriptname[i]))
            
        #----------------
        # Hyperthreaded
        #----------------
        else:
            # Just make batch file
            # treat shell and idl the same
            # The execution command
            cmd = input[i]
            # If there are commas in the line then break it up into multiple
            # lines
            if cmd.find(';') != -1: cmd=cmd.split(';')
            # IDL files should end in .batch
            if idle is True: scriptname[i] = str(indir[i])+'/'+base+'.batch'
            # Writing the file
            writelines(scriptname[i],cmd)
            # Make SHELL scripts executable
            if idle is False: os.chmod(scriptname[i],0755)
            # Print info
            print('HYPERTHREAD script written to: '+str(scriptname[i]))

    # Erase the temporary files that MAKETEMP makes
    remove(name,allow=True)

    return scriptname


def submitjob(idle=False,hyperthread=True):
    """ This submits new jobs. """
    curdir = os.getcwd()
    # Submitting the job
    if hypterthread is False:
        out = subprocess.check_output(['qsub',scriptname[0]],stderr=subprocess.STDOUT,shell=False)        
        jobid = out[0]
        logfile = scriptname[0]+'.log'
    else:
        if idle is True:
            batchprog = './idlbatch'
        else:
            batchprog = './runbatch'
        if cdtodir is True: os.chdir(dirs[newind[i]])
        out = subprocess.check_output([batchprog,scriptname[0]],stderr=subprocess.STDOUT,shell=False)
        if cdtodir is True: os.chdir(curdir)
        # Get the JOBID
        jobid_ind = np.where(grep(out,'^JOBID=',/boolean)==1)
        njobid_ind = len(jobid_ind)
        jobid = strmid(out[jobid_ind[0]],6)        
        # Get the logfile
        logfile_ind = np.where(stregex(out,'^Log file: ',/boolean) eq 1,nlogfile_ind)
        logfile = strmid(out[logfile_ind[0]],10)

    # Check that there weren't any errors
    dum, = np.where(errout!='')
    nerror = len(dum)

    # Printing info
    print('Submitted '+scriptname[0]+'  JobID='+jobid[0])


def checkstat(statstr=None,jobid=None,hyperthread=True):
    """Check the status of jobs

    This checks the status of jobs for the job_daemon program.
    If no jobs are found in the queue then an empty
    statstr structure is returned.

    INPUTS:
    =jobid   Specific JOBID to check.
    /stp     Stop at the end of the program.
    /hyperthread  Not on a PBS machine but one with multipe hyperthreaded
                    processors running simultaneously.

    OUTPUTS:
    statstr  Stat structure.

    USAGE:
    IDL>job_checkstat,statstr,jobid=jobid,stp=stp

    By D.Nidever   February 2008
    Updated for LSST stack  Nov 2015
    """
    if statstr is None: raise ValueError("Must in put statstr")
    if jobid is None: njob=0 else njob=np.array(jobid).size

    # PBS
    #--------
    if hyperthread is False:
        if njobid>0: 
            out = subprocess.check_output(['qstat',jobid[0]],stderr=subprocess.STDOUT,shell=False)
        else:
            out = subprocess.check_output(['qstat'],stderr=subprocess.STDOUT,shell=False)
        dum, = np.where(out ne '')
        nout = len(dum)
        gd, = np.where(stregex(out,'^'+jobid,/boolean)==1)
        ngd = len(gd)
        if ngd>0:
            statlines = out[gd[0]]
            nstat = len(statlines)
        else:
            statlines = None
        # Some jobs in queue
        if statlines is not None:
            arr = statlines
            arr = arr.split(' ')
            statstr = mkstatstr(nstat)
            statstr['jobid'] = arr[0]
            statstr['name'] = arr[1]
            statstr['user'] = arr[2]
            statstr['timeuse'] = arr[3]
            statstr['status'] = arr[4]
            statstr['queue'] = arr[5]
        # No jobs in queue
        else:
            statstr = mkstatstr(1)

    # Hyperthreaded.  Need a jobid
    #-----------------------------
    else:
        # No JOBID input
        if njobid==0:
            print('Need JOBID with /hyperthread')
            return mkstatstr(1)

        out = subprocess.check_output(['ps','-o','pid,user,etime,command','-p',str(jobid[0])],
                                      stderr=subprocess.STDOUT,shell=False)
        # can put in the column that you want
        # ps -o etime -p jobid
        out = [o.strip() for o in out]
        gd = where(stregex(out,'^'+strtrim(jobid,2),/boolean) eq 1,ngd)
        if ngd>0:
            statlines = out[gd[0]]
            nstat = len(statlines)
        else:
            statlines = None
        # Some jobs in queue
        if statlines is not None:
            arr = statlines.split()
            statstr = mkstatstr(nstat)
            statstr['jobid'] = arr[0]
            statstr['user'] = arr[1]
            # CAN'T get the name.
            statstr['timeuse'] = arr[2]
            statstr['status'] = 'R'
            statstr['queue'] = 'hyperthread'
        # No jobs in queue
        else:
            statstr = mkstatstr(1)

    return statstr


def job_daemon(input=None,dirs=None,inpname=None,idle=False,prefix=None,nmulti=1,hyperthread=True,
               cdtodir=False,waittime=0.2,statustime=60)
    """This program is a simple batch job manager

    NOTE:  If you want to "kill" all of the jobs create a file "killjobs"
    in the same directory that JOB_DAEMON is being run in and all of the
    PBS jobs will be killed.

    INPUTS:
    input     A string array with the IDL commands (i.e. jobs) to be run.
    dirs      The directories in which the commands are to be run.
    /idle     This is an IDL command, otherwise a SHELL command.
    =prefix   The prefix for the PBS script names
    =nmulti   How many nodes to run these jobs on.  Default is 8.
    /hyperthread  Not on a PBS server but one that has multiple processors
                   hyperthreaded.  Run multiple jobs at the same time on
                   the same server.
    =inpname  The name to be used for the script (without the path or
                   the .sh/.batch ending.  This is normally autogenerated.
    =statustime   The time between status updates.  However, the status
                    will always be updated if something has actually changed.
    =waittime     Time to wait between checking the running jobs.  Default
                    is 0.2 sec.

    OUTPUTS:
    =jobs      The jobs structure with information on the JOBID, script
                name, etc.
    Jobs are run in a batch mode.

    USAGE:
    IDL>job_daemon,input,dirs,jobs=jobs,idle=idle,prefix=prefix,nmulti=nmulti

    """

    # How many input lines
    if input is None:
        raise ValueError("Nothing input")
    ninput = np.array(input).size

    # Current directory
    curdir = os.getcwd()

    # Checking DIRS array
    if dirs is None:
        dirs = np.repeat(curdir,ninput)
    else:
        ndirs = np.array(dirs).size
        if ndirs!=ninput:
            raise ValueError('DIRS array must be same size as INPUT')            
        if ndirs==1: dirs = np.repeat(dirs,ninput)

    # Check INPNAME array
    ninpname = len(inpname)
    if ninpname gt 0 then if ninpname ne ninput:
        error = 'INPNAME array must be same size as INPUT'
        print,error
        return

    # Defaults
    if waittime<0.1: waittime=0.1
    if statustime<1: statustime=1

    # Host name
    hostname = socket.gethostname()
    host = hostname.split('.')[0]

    # Which IDL are we using?
    if idle is true:
        try:
            out = subprocess.check_output(['which','idl'],stderr=subprocess.STDOUT,shell=False)
        except subprocess.CalledProcessError, e:
            raise Exception("IDL program not available")
        idlprog = out.strip()
        if os.path.exists(idlprog) is False:
            raise Exception("IDL program "+idlprog+" not found")

    # Create RUNBATCH and IDLBATCH if using /hyperthread
    if (hyperthread is True):
        if (idle is False) & (os.path.exists('runbatch') is False):
            lines = []
            lines.append("if test $# -eq 0\n")
            lines.append("then\n")
            lines.append("  echo 'Syntax - runbatch program'\n")
            lines.append("else\n")
            lines.append("  echo 'Log file: '$1'.log'\n")
            lines.append("  ( nohup  $1 > $1.log 2>&1 ) &\n")
            lines.append("  echo JOBID=$!\n")
            lines.append("fi\n")
            writelines('runbatch',lines)
            os.chmod('runbatch',0755)
        if (idle is True) & (os.path.exists('idlbatch') is False):
            lines = []
            lines.append("if test $# -eq 0\n")
            lines.append("then\n")
            lines.append("  echo 'Syntax - idlbatch idl.batch'\n")
            lines.append("else\n")
            lines.append("  echo 'Log file: '$1'.log'\n")
            lines.append("  ( nohup "+idlprog+" < $1 > $1.log 2>&1 ) &\n")
            lines.append("  echo JOBID=$!\n")
            lines.append("fi\n")
            writelines('idlbatch',lines)
            os.chmod('idlbatch',0755)

    print('---------------------------------')
    print(' RUNNING JOB_DAEMON for '+str(ninput)+' JOB(S)')
    print('---------------------------------')
    print('Host='+host)
    print('Nmulti='+str(nmulti))
    
    t0 = time.time()
    timesincelaststatus = time.time()  # initializing the update time

    #--------
    # DAEMON
    #--------
    # -Keep submitting jobs until nmulti is reached
    # -Check every minute or so to see how many jobs are still
    #  running.  If it falls below nmulti and more jobs are left then
    #  submit more jobs
    # -Don't return until all jobs are done.

    # Initialize the "jobs" structure
    # id will be the ID from Pleione
    jobs = mkjobstr(ninput)
    jobs['input'] = input
    njobs = ninput

    # Loop until all jobs are done
    # On each loop check the pleione queue and figure out what to do
    count = np.longlong(0)
    endflag = 0
    while (endflag==0):
        # Status update
        dtstatus_sec = ( time.time()-timesincelaststatus )*3600L*24L
        if (dtstatus_sec>statustime):
            updatestatus = True
            timesincelaststatus = time.time()
            print('')
            print(time.ctime())
        else:
            updatestatus = False
  
        # Check disk space
        check_diskspace()

        # Check for kill file
        check_killfile()
  
        # Check status of running jobs
        #-----------------------------
        sub, = np.where((jobs['submitted'] is True) & (jobs['done'] is False))
        nsub = len(sub)
        for i in range(nsub):
            # Checking status
            jobid = jobs[sub[i]]['jobid']
            statstr = checkstat(jobid,hyperthread=hyperthread)
            # Job done
            if statstr['jobid']=='':
                print,systime(0)+'  Input ',strtrim(sub[i]+1,2),' ',jobs[sub[i]].name,' JobID=',jobs[sub[i]].jobid,' FINISHED'
                jobs[sub[i]]['done'] = True
                jobs[sub[i]]['endtime'] = time.time()
                jobs[sub[i]]['duration'] = ( jobs[sub[i]]['endtime'] - jobs[sub[i]]['begtime'] )*3600*24 # in sec
            # Check for errors as well!! and put in jobs structure

        # Current status
        #---------------
        n_inqueue = np.sum((jobs['submitted'] is True) & (jobs['done'] is False))  # Number of jobs still in queue  
        n_nosubmit = np.sum(jobs['submitted'] is False)                            # Number of jobs left to do 
        n_finished = np.sum(jobs['done'] is True)                                  # Number of jobs finished 
        # Print the status
        if updatestatus is True:
            print('Jobs Summary: %d total, %d, finished, %d running, %d left') % (n_input,n_finished,n_inqueue,n_nosubmit))

        # Submit new jobs
        #----------------
        nnew = limit(nmulti-n_inqueue,0,nosubmit)
        if (nnew>0):
            # Get the indices of new jobs to be submitted
            nosubmit, = np.where(jobs['submitted'] is False)
            newind = nosubmit[0:nnew]
            # Update immediately if there are new jobs to submit
            print('')
            print(time.ctime())
            print('Updating Queue: '+str(n_inqueue)+' JOB(S) running, out of '+str(nmulti)+' Maximum. Submitting '+str(nnew)+' more job(s)'

            # Loop through the new submits
            for i in range(nnew):
                print('')
                cmd = jobs[newind[i]]['input']
                if idle is True: cmd = 'IDL>'+str(cmd)
                # Update immediately
                print('Input '+str(newind[i]+1)+'  Command: >>'+str(cmd)+'<<'
                # Make script
                if ninpname gt 0 then name=inpname[newind[i]]  # use input name
                makescript(jobs[newind[i]]['input'],dir=dirs[newind[i]],name=name,scriptname=scriptname,
                               prefix=prefix,idle=idle,hyperthread=hyperthread)
                # Check that the script exists
                test = FILE_TEST(scriptname)

                # Submitting the job
                submitjob()

                # Updating the jobs structure
                jobs[newind[i]]['submitted'] = True
                jobs[newind[i]]['jobid'] = jobid
                jobs[newind[i]]['name'] = name[0]
                jobs[newind[i]]['dir'] = dirs[newind[i]]
                jobs[newind[i]]['scriptname'] = scriptname[0]
                jobs[newind[i]]['logfile'] = logfile
                jobs[newind[i]]['begtime'] = time.time()

        print('')
        # Are we done?
        #-------------
        ndone = np.sum(jobs['done'] is True)
        if (ndone==njobs): endflag=1
        # Wait a bit
        #--------------
        if (endflag==0): time.sleep(waittime)
        # Increment the counter
        count += 1

    print('DONE')
    print('dt = '+str(time.time()-t0)+' sec')
    return jobs
