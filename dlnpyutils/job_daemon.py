#!/usr/bin/env python
#
# JOB_DAEMON.PY - Simple batch job manager.
#

from __future__ import print_function

__authors__ = 'David Nidever <dnidever@noao.edu>'
__version__ = '20181010'  # yyyymmdd

import os
import sys
import numpy as np
import warnings
#from astropy.io import fits
#from astropy.wcs import WCS
#from astropy.utils.exceptions import AstropyWarning
#from astropy.table import Table, Column
import time
#import shutil
import subprocess
#import logging
#import astropy.stats
#import struct
#import tempfile
from dlnpyutils.dlnpyutils import *

        
def mkjobstr(n=None):
    """ This returns the job structure schema or an instance of the job structure."""
    dtype = np.dtype([('jobid',np.str,20),('name',np.str,100),('user',np.str,100),('timeuse',np.str,100),('status',np.str),('queue',np.str)])
    if n is None:
        return dtype
    else:
        statstr = np.zeros(n,dtype=dtype)    
        return statstr


def check_diskspace(indir=None,updatestatus=False):
    """ This checks if there's enough free disk space. """
    if indir is None: raise ValueError("Must give directory")
    statvfs = os.statvfs(indir)
    available = statvfs.f_frsize * statvfs.f_bavail / 1e6  # in MB
    if updatestatus: print,'Disk Space: '+str(available[0]),' MB available'
    # Not enough disk space available
    if available<100.:
        raise Exception('NOT enough disk space available')


def check_killfile(jobs=None,hyperthread=True):
    """ This checks for a kill file and if found kills all the active jobs. """
    if jobs is None: raise ValueError("No jobs structure input")
    killfile = 'killjobs'
    kill = os.path.exists(killfile)
    if (kill==1):
        sub = np.where((jobs['submitted']==1) & (jobs['done']==0))
        nsub = len(sub)
        print('Kill file found.  Killing all '+str(nsub)+' job(s)')
        for i=0,nsub-1:
            # Killing the job
            print('Killing '+jobs[sub[i]]['name']+'  JobID='+jobs[sub[i]]['jobid'])
            if hypterthread is False:
                out = subprocess.check_output(['qdel',jobs[sub[i]]['jobid']],stdout=sf,stderr=subprocess.STDOUT,shell=False)
            else:
                out = subprocess.check_output(['kill','-9',jobs[sub[i]]['jobid']],stderr=subprocess.STDOUT,shell=False)
        # Remove the kill file
        print('Deleting kill file "'+killfile+'"')
        os.remove(killfile)
        sys.exit()


def makescript(input=None,indir=None,name=None,scriptname=None,idle=False,prefix=None,hyperthread=True)
    """This makes job scripts for the job_daemon program.

    Parameters
    ----------
    input : string list or array
          The command to execute.  Can be an array.  idlbatch will
          be used if it's an IDL command.  If the command is a
          series of unix commands separated by commas then these
          will be put on separate lines.
    indir : string list or array
          The directory to put the job script in.
    name : string list or array, optional
          The name to call the job script (without the '.sh' or '.batch' ending).
          If this is not provided then an autogenerated name will
          be made and returned.
    idle : bool, optional
          This is an IDL command, otherwise a SHELL command.
    prefix : string, optional
          The prefix to use for the job script name. "pr" by default.
    hyperthread : bool 
          Not on a job server but one with multiple hyperthreaded
                   processors.

    Returns
    -------
    scriptname : string array
               The absolute names of the scripts.
    Job scripts output to the directories and with the names specified.


    Example
    -------

    .. code-block:: python

        scriptname = makescript(input,dir,name,hyperthread=True)

    """
  
    # Not enough inputs
    if (input is None):
        raise ValueError('No input given')

    ninput = np.array(input).size
    if indir is not None: ndir=np.array(indir).size else ndir=0
    if name is not None: nname=np.array(name).size else nname=0

    # Not enough directories input
    if (ndir>0) & (ndir!=ninput):
        raise ValueError('INPUT and DIRECTORIES are of different size')

    # Current directory
    curdir = os.getcwd()

    # No directories input
    if ndir==0: indir = np.repeat(curdir,ninput)
    if ndir==1: indir = np.repeat(indir,ninput)    # multiple commands in same dir

    # Construct names
    if (nname==0):
        name = np.zeros(ninput,dtype=(np.str,200))
        if prefix is not None:
            pre = prefix[0]
        else:
            pre = 'job'
        for i in range(ninput):
            tid,tfile = tempfile.mkstemp(prefix=pre,dir=indir[i])
            os.close(tid)   # mkstemp opens the file, close it
            name[i] = tfile

    # Make scriptnames
    scriptname = strjoin(strjoin(indir,name),'.sh')
    scriptname = indir+'/'+name+'.sh'
    # Script loop
    for i in range(ninput):
        base = name[i]
        sname = indir[i]+'/'+base+'.sh'

        #------
        # PBS
        #------
        if hyperthread is False:
            # IDL command
            if idle is True:
                # Making an IDL batch file
                bname = indir[i]+'/'+base+'.batch'
                writelines(bname,input[i])
                # The execution command
                cmd = 'idl < '+base+'.batch'
            # SHELL command
            else:
                # The execution command
                cmd = input[i]
                # If there are commas in the line then break it up into multiple lines
                if cmd.find(';') != -1: cmd = cmd.split('j')

            # Make the command
            #----------------------
            lines = []
            lines.append('#!/bin/sh\n')
            lines.append('#PBS -l nodes=1:ppn=1\n')
            lines.append('#PBS -l walltime=96:00:00\n')
            lines.append('#PBS -o '+base+'.report.out\n')
            lines.append('#PBS -e '+base+'.error.out\n')
            lines.append('#PBS -M dln5q@virginia.edu\n')
            lines.append('#PBS -V\n')
            lines.append('\n')
            lines.append('echo Running on host `hostname`\n')
            lines.append('echo Time is `date`\n')
            lines.append('echo "Nodes used for this job:"\n')
            lines.append('echo "------------------------"\n')
            lines.append('cat $PBS_NODEFILE\n')
            lines.append('echo "------------------------"\n')
            lines.append('\n')
            lines.append('cd '+indir[i]+'\n')
            for j=0,len(cmd)-1 do lines.append(cmd[j]+'\n')
            lines.append('\n')
            lines.append('# print end time\n')
            lines.append('echo\n')
            lines.append('echo "Job Ended at `date`"\n')
            lines.append('echo\n')
            # Writing the file
            writelines(scriptname[i],lines)
            # Print info
            print('PBS script written to: '+scriptname[i])
            
        #----------------
        # Hyperthreaded
        #----------------
        else:
            # Just make batch file
            # treat shell and idl the same
            # The execution command
            cmd = input[i]
            # If there are commas in the line then break it up into multiple
            # lines
            if cmd.find(';') != -1: cmd=cmd.split(';')
            # IDL files should end in .batch
            if idle is True: scriptname[i]=indir[i]+'/'+base+'.batch'
            # Writing the file
            writelines(scriptname[i],cmd)
            # Make SHELL scripts executable
            if idle is False: FILE_CHMOD,scriptname[i],'755'o
            # Print info
            print('HYPERTHREAD script written to: '+scriptname[i])

    # Erase the temporary files that MAKETEMP makes
    file_delete,name,/allow
    # Go back to original directory
    CD,curdir

    return scriptname

def submitjob(idle=False,hyperthread=True):
    """ This submits new jobs. """
    # Submitting the job
    if hypterthread is False:
        out = subprocess.check_output(['qsub',scriptname[0]],stderr=subprocess.STDOUT,shell=False)        
        jobid = out[0]
        logfile = scriptname[0]+'.log'
    else:
        if idle is True: batchprog='./idlbatch' else: batchprog='./runbatch'
        if cdtodir is True: cd,dirs[newind[i]]
        out = subprocess.check_output([batchprog,scriptname[0]],stderr=subprocess.STDOUT,shell=False)
        if cdtodir is True: cd,curdir
        # Get the JOBID
        jobid_ind = np.where(grep(out,'^JOBID=',/boolean)==1)
        njobid_ind = len(jobid_ind)
        jobid = strmid(out[jobid_ind[0]],6)        
        # Get the logfile
        logfile_ind = np.where(stregex(out,'^Log file: ',/boolean) eq 1,nlogfile_ind)
        logfile = strmid(out[logfile_ind[0]],10)

    # Check that there weren't any errors
    dum = where(errout ne '',nerror)

    # Printing info
    print('Submitted '+scriptname[0]+'  JobID='+jobid[0])


def checkstat(statstr=None,jobid=None,hyperthread=True):
    """Check the status of jobs

    This checks the status of jobs for the job_daemon program.
    If no jobs are found in the queue then an empty
    statstr structure is returned.

    INPUTS:
    =jobid   Specific JOBID to check.
    /stp     Stop at the end of the program.
    /hyperthread  Not on a PBS machine but one with multipe hyperthreaded
                    processors running simultaneously.

    OUTPUTS:
    statstr  Stat structure.

    USAGE:
    IDL>job_checkstat,statstr,jobid=jobid,stp=stp

    By D.Nidever   February 2008
    Updated for LSST stack  Nov 2015
    """
    if statstr is None: raise ValueError("Must in put statstr")
    if jobid is None: njob=0 else njob=np.array(jobid).size

    # PBS
    #--------
    if hyperthread is False:
        if njobid>0: 
            out = subprocess.check_output(['qstat',jobid[0]],stderr=subprocess.STDOUT,shell=False)
        else:
            out = subprocess.check_output(['qstat'],stderr=subprocess.STDOUT,shell=False)
        dum, = np.where(out ne '')
        nout = len(dum)
        gd, = np.where(stregex(out,'^'+jobid,/boolean)==1)
        ngd = len(gd)
        if ngd>0:
            statlines = out[gd[0]]
            nstat = len(statlines)
        else:
            statlines = None
        # Some jobs in queue
        if statlines is not None:
            arr = statlines
            arr = strsplitter(statlines,' ',/extract)
            statstr = jobstr
            statstr = mkjobstr(nstat)
            statstr['jobid'] = arr[0]
            statstr['name'] = arr[1]
            statstr['user'] = arr[2]
            statstr['timeuse'] = arr[3]
            statstr['status'] = arr[4]
            statstr['queue'] = arr[5]
        # No jobs in queue
        else:
            statstr = mkjobstr(1)

    # Hyperthreaded.  Need a jobid
    #-----------------------------
    else:
        # No JOBID input
        if njobid==0:
            print('Need JOBID with /hyperthread')
            return mkjobstr(1)

        out = subprocess.check_output(['ps','-o','pid,user,etime,command','-p',str(jobid[0])],
                                      stderr=subprocess.STDOUT,shell=False)
        # can put in the column that you want
        # ps -o etime -p jobid
        out = [o.strip() for o in out]
        gd = where(stregex(out,'^'+strtrim(jobid,2),/boolean) eq 1,ngd)
        if ngd>0:
            statlines = out[gd[0]]
            nstat = len(statlines)
        else:
            statlines = None
        # Some jobs in queue
        if statlines is not None:
            arr = statlines.split()
            statstr = mkjobstr(nstat)
            statstr['jobid'] = arr[0]
            statstr['user'] = arr[1]
            # CAN'T get the name.
            statstr['timeuse'] = arr[2]
            statstr['status'] = 'R'
            statstr['queue'] = 'hyperthread'
        # No jobs in queue
        else:
            statstr = mkjobstr(1)

    return statstr


def job_daemon(input,dirs,jobs=jobs,idle=idle,prefix=prefix,nmulti=nmulti,
               hyperthread=hyperthread,waittime=waittime,statustime=statustime,
               inpname=inpname,cdtodir=cdtodir)
    """This program is a simple batch job manager

    NOTE:  If you want to "kill" all of the jobs create a file "killjobs"
    in the same directory that JOB_DAEMON is being run in and all of the
    PBS jobs will be killed.

    INPUTS:
    input     A string array with the IDL commands (i.e. jobs) to be run.
    dirs      The directories in which the commands are to be run.
    /idle     This is an IDL command, otherwise a SHELL command.
    =prefix   The prefix for the PBS script names
    =nmulti   How many nodes to run these jobs on.  Default is 8.
    /hyperthread  Not on a PBS server but one that has multiple processors
                   hyperthreaded.  Run multiple jobs at the same time on
                   the same server.
    =inpname  The name to be used for the script (without the path or
                   the .sh/.batch ending.  This is normally autogenerated.
    =statustime   The time between status updates.  However, the status
                    will always be updated if something has actually changed.
    =waittime     Time to wait between checking the running jobs.  Default
                    is 0.2 sec.

    OUTPUTS:
    =jobs      The jobs structure with information on the JOBID, script
                name, etc.
    Jobs are run in a batch mode.

    USAGE:
    IDL>job_daemon,input,dirs,jobs=jobs,idle=idle,prefix=prefix,nmulti=nmulti

    """

  
    # How many input lines
    ninput = len(input)
    if ninput eq 0:
        error = 'Not enough inputs'
        print,'Syntax - job_daemon,input,dirs,jobs=jobs,idle=idle,prefix=prefix,nmulti=nmulti,'
        print,'                    hyperthread=hyperthread,waittime=waittime,statustime=statustime,'
        print,'                    inpname=inpname,error=error'
        return

        # Current directory
        CD,current=curdir

        # Checking DIRS array
        ndirs = len(dirs)
        if ndirs gt 0 then if ndirs ne ninput:
        error = 'DIRS array must be same size as INPUT'
        print,error
        return
    if ndirs eq 0 then dirs = replicate(curdir,ninput)
    if ndirs eq 1 then dirs = replicate(dirs,ninput)

    # Check INPNAME array
    ninpname = len(inpname)
    if ninpname gt 0 then if ninpname ne ninput:
        error = 'INPNAME array must be same size as INPUT'
        print,error
        return

    # Defaults
    if len(nmulti) eq 0 then nmulti=8           # number of jobs to submit at a time
    if len(waittime) eq 0 then waittime=0.2     # wait time
    waittime = waittime > 0.1
    if len(statustime) eq 0 then statustime=60  # status time
    statustime = statustime > 1

    # Host name
    host = getenv('HOST')

    # Which IDL are we using?
    if keyword_set(idle):
        SPAWN,['which','idl'],out,errout,/noshell
        if STRPOS(out[0],'aliased to') ne -1 then $
        out = first_el(strsplit(out[0],' ',/extract),/last)
        idlprog = FILE_SEARCH(out[0],count=nidlprog)
        if (nidlprog eq 0):
            error = 'IDL PROGRAM NOT AVAILABLE'
            print,error
            return

    # Create RUNBATCH and IDLBATCH if using /hyperthread
    if keyword_set(hyperthread):
        if (idle is False) & (os.path.exists('runbatch') is False):
            lines = []
            lines.append("if test $# -eq 0\n")
            lines.append("then\n")
            lines.append("  echo 'Syntax - runbatch program'\n")
            lines.append("else\n")
            lines.append("  echo 'Log file: '$1'.log'\n")
            lines.append("  ( nohup  $1 > $1.log 2>&1 ) &\n")
            lines.append("  echo JOBID=$!\n")
            lines.append("fi\n")
            writelines('runbatch',lines)
            FILE_CHMOD,'runbatch','755'o
        if (idle is True) & (os.path.exists('idlbatch') is False):
            lines = []
            lines.append("if test $# -eq 0\n")
            lines.append("then\n")
            lines.append("  echo 'Syntax - idlbatch idl.batch'\n")
            lines.append("else\n")
            lines.append("  echo 'Log file: '$1'.log'\n")
            lines.append("  ( nohup "+idlprog+" < $1 > $1.log 2>&1 ) &\n")
            lines.append("  echo JOBID=$!\n")
            lines.append("fi\n")
            writelines('idlbatch',lines)
            FILE_CHMOD,'idlbatch','755'o

    print('---------------------------------')
    print(' RUNNING JOB_DAEMON for '+str(ninput)+' JOB(S)')
    print('---------------------------------')
    print('Host='+host)
    print('Nmulti='+str(nmulti))
    
    timesincelaststatus = time.time()  # initializing the update time


    #--------
    # DAEMON
    #--------

    # -Keep submitting jobs until nmulti is reached
    # -Check every minute or so to see how many jobs are still
    #  running.  If it falls below nmulti and more jobs are left then
    #  submit more jobs
    # -Don't return until all jobs are done.


    # Initialize the "jobs" structure
    # id will be the ID from Pleione
    dum = {host:host,jobid:'',input:'',dir:'',name:'',scriptname:'',logfile:'',submitted:0,done:0,$
           begtime:0.0d0,endtime:0.0d0,duration:0.0}
    jobs = replicate(dum,ninput)
    jobs.input = input
    njobs = ninput

    # Loop until all jobs are done
    # On each loop check the pleione queue and figure out what to do
    count = 0LL
    endflag = 0
    WHILE (endflag eq 0):

        # Status update
        dtstatus_sec = ( time.time()-timesincelaststatus )*3600L*24L
        if dtstatus_sec>statustime:
            updatestatus = 1
            timesincelaststatus = time.time()
            print('')
            print(time.ctime())
        else:
            updatestatus = 0
  
        # Check disk space
        check_diskspace()

        # Check for kill file
        check_killfile()
  
        # Check status of running jobs
        #-----------------------------
        sub = where(jobs.submitted eq 1 and jobs.done eq 0,nsub)
        for i=0,nsub-1:

            # Checking status
            jobid = jobs[sub[i]].jobid
            JOB_CHECKSTAT,statstr,jobid=jobid,hyperthread=hyperthread

            # Job done
            if statstr.jobid eq '':
                print,systime(0)+'  Input ',strtrim(sub[i]+1,2),' ',jobs[sub[i]].name,' JobID=',jobs[sub[i]].jobid,' FINISHED'
                jobs[sub[i]].done=1
                jobs[sub[i]].endtime = systime(/julian,/utc)
                jobs[sub[i]].duration = ( jobs[sub[i]].endtime - jobs[sub[i]].begtime )*3600*24 # in sec

            # Check for errors as well!! and put in jobs structure

        # Current status
        #---------------
        dum = where(jobs.submitted eq 1 and jobs.done eq 0,Ninqueue)  # Number of jobs still in queue
        dum = where(jobs.submitted eq 0,Nnosubmit)                    # Number of jobs left to do
        dum = where(jobs.done eq 1,nfinished)                         # Number of jobs finished
        # Print the status
        if updatestatus: print('Jobs Summary: ',strtrim(ninput,2),' total, ',strtrim(nfinished,2),
                                   ' finished, ',strtrim(Ninqueue,2),' running, ',strtrim(Nnosubmit,2),' left')

        # Submit new jobs
        #----------------
        Nnew = (nmulti-ninqueue) > 0
        Nnew = Nnew < Nnosubmit
        If (Nnew gt 0):

            # Get the indices of new jobs to be submitted
            nosubmit = where(jobs.submitted eq 0)
            newind = nosubmit[0:nnew-1]

            # Update immediately if there are new jobs to submit
            print,''
            print,systime(0)
            print,'Updating Queue: '+strtrim(ninqueue,2),' JOB(S) running, out of ',strtrim(nmulti,2),' Maximum. Submitting ',strtrim(nnew,2),' more job(s)'

            # Loop through the new submits
            For i=0,nnew-1:

                print,''
                cmd = jobs[newind[i]].input
                if keyword_set(idle) then cmd='IDL>'+cmd
                # Update immediately
                print,'Input ',strtrim(newind[i]+1,2),'  Command: >>',cmd,'<<'

                # Make script
                lsst_undefine,name,scriptname
                if ninpname gt 0 then name=inpname[newind[i]]  # use input name
                makescript(jobs[newind[i]].input,dir=dirs[newind[i]],name=name,scriptname=scriptname,
                               prefix=prefix,idle=idle,hyperthread=hyperthread)
                # Check that the script exists
                test = FILE_TEST(scriptname)

                # Submitting the job
                submitjob()

                # Updating the jobs structure
                jobs[newind[i]].submitted = 1
                jobs[newind[i]].jobid = jobid
                jobs[newind[i]].name = name[0]
                jobs[newind[i]].dir = dirs[newind[i]]
                jobs[newind[i]].scriptname = scriptname[0]
                jobs[newind[i]].logfile = logfile
                jobs[newind[i]].begtime = systime(/julian,/utc)

        print,''

    # Are we done?
    #-------------
    dum = where(jobs.done eq 1,ndone)
    if ndone eq njobs then endflag=1

    # Wait a bit
    #--------------
    if endflag eq 0 then wait,waittime

    # Increment the counter
    count++
